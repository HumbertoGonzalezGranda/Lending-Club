{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select(query):\n",
    "    \n",
    "    conn = sqlite3.connect('./data/lending-club-loan-data/database2.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    temp_df = pd.DataFrame(cursor.execute(query).fetchall())\n",
    "    temp_df.columns = list(map(lambda x: x[0], cursor.description))\n",
    "    conn.close()\n",
    "    \n",
    "    return temp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train = select('SELECT * FROM FEATURES_TRAIN')\n",
    "targets_train = select('SELECT * FROM TARGETS_TRAIN')\n",
    "features_test = select('SELECT * FROM FEATURES_TEST')\n",
    "targets_test = select('SELECT * FROM TARGETS_TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2153942473241268"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data has approx 1:5 ratio of minority to majority class examples\n",
    "\n",
    "ratio = -1*((targets_train.loan_status-1).sum())/targets_train.loan_status.sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Manipulation approach 1: Undersampling of the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_dict1: undersample the majority class to create a 1:1 ratio of minority to majority class examples\n",
    "# ratio_dict2: undersample the majority class to create a 2:1 ratio of minority to majority class examples\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ratio_dict1 = {0:len(features_train[~targets_train.astype(bool).loan_status]),\\\n",
    "               1:len(features_train[~targets_train.astype(bool).loan_status])}\n",
    "ratio_dict2 = {0:len(features_train[~targets_train.astype(bool).loan_status]),\\\n",
    "                1:round((.5*len(features_train[~targets_train.astype(bool).loan_status])))}\n",
    "\n",
    "features_res1, targets_res1 = RandomUnderSampler(ratio=ratio_dict1,random_state=2)\\\n",
    "    .fit_sample(features_train,targets_train.loan_status)\n",
    "    \n",
    "features_res2, targets_res2 = RandomUnderSampler(ratio=ratio_dict2,random_state=2)\\\n",
    "    .fit_sample(features_train,targets_train.loan_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1 minority to majority class undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641775963863\n"
     ]
    }
   ],
   "source": [
    "# accuracy considerably drops -- this same baseline model in pt1 had 82% accuracy on the test set\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_res1,targets_res1)\n",
    "print(accuracy_score(lr.predict(features_test),targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LR\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.64      0.64     35780\n",
      "          1       0.64      0.65      0.65     35780\n",
      "\n",
      "avg / total       0.64      0.64      0.64     71560\n",
      "\n",
      "TEST LR\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.63      0.38      8929\n",
      "          1       0.89      0.64      0.75     41545\n",
      "\n",
      "avg / total       0.78      0.64      0.68     50474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# precision drops from 50% to 28%, but this model in pt1 only made 4 negative class predictions. there remains room for\n",
    "# improvement in precision, but model has become much more sensitive to outputting the minority class\n",
    "# recall is GREATLY improved -- this model in pt1 has close to 0% recall on the test set\n",
    "\n",
    "print('TRAIN LR')\n",
    "print(classification_report(targets_res1,lr.predict(features_res1)))\n",
    "print('TEST LR')\n",
    "print(classification_report(targets_test,lr.predict(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.57      0.37      8929\n",
      "          1       0.88      0.68      0.77     41545\n",
      "\n",
      "avg / total       0.77      0.66      0.70     50474\n",
      "\n",
      "kNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.54      0.29      8929\n",
      "          1       0.85      0.54      0.66     41545\n",
      "\n",
      "avg / total       0.73      0.54      0.60     50474\n",
      "\n",
      "RF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.26      0.65      0.37      8929\n",
      "          1       0.89      0.61      0.72     41545\n",
      "\n",
      "avg / total       0.78      0.62      0.66     50474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# increase the number of trees in RF from default 10 to 64\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "GNB = GaussianNB().fit(features_res1,targets_res1)\n",
    "KNN = KNeighborsClassifier().fit(features_res1,targets_res1)\n",
    "RF = RandomForestClassifier(n_estimators=64).fit(features_res1,targets_res1)\n",
    "\n",
    "# metrics are for the test set only, for: Gaussian NB, kNN, and Random Forest classifiers\n",
    "\n",
    "# unlike the case without undersampling, these three models offer little performance improvement in any of the metrics\n",
    "# over logistic regression. undersampling seems to greatly improve logistic regression's performance, bringing it up to par\n",
    "# with other algorithms (a bit better, even). still, the other algorithms have notable performance gains from undersampling\n",
    "\n",
    "print('GNB')\n",
    "print(classification_report(targets_test,GNB.predict(features_test)))\n",
    "print('kNN')\n",
    "print(classification_report(targets_test,KNN.predict(features_test)))\n",
    "print('RF')\n",
    "print(classification_report(targets_test,RF.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2:1 minority to majority class undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278341324246\n"
     ]
    }
   ],
   "source": [
    "# accuracy is concerningly low..perhaps we are sacrificing too much in the recall of positive examples\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(features_res2,targets_res2)\n",
    "print(accuracy_score(lr2.predict(features_test),targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.96      0.80     35780\n",
      "          1       0.62      0.13      0.22     17890\n",
      "\n",
      "avg / total       0.67      0.68      0.61     53670\n",
      "\n",
      "TEST             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.96      0.32      8929\n",
      "          1       0.94      0.13      0.23     41545\n",
      "\n",
      "avg / total       0.81      0.28      0.25     50474\n",
      "\n",
      "test set negative class predictions: 44622\n",
      "test set positive class predictions: 5852\n"
     ]
    }
   ],
   "source": [
    "# recall on the negative class is extremely good, but we have sacrificed too much predictability on the majority class\n",
    "# (the negative class precision is quite low on the test set..the model is now insensitive to positive predictions)\n",
    "\n",
    "# there seems to be a balance that we can achieve between metric performance on positive/negative examples\n",
    "# by changing the ratio of minority to majority class examples, but ideally we want to perform well on both\n",
    "\n",
    "# rather than simply adjusting the ratio of class examples, we move onto other resampling techniques and applying\n",
    "# different algorithms w/ hyperparameter optimization to aim for better performance on both metrics on both classes\n",
    "\n",
    "print('TRAIN'+classification_report(targets_res2,lr2.predict(features_res2)))\n",
    "print('TEST'+classification_report(targets_test,lr2.predict(features_test)))\n",
    "\n",
    "print('test set negative class predictions: '+str((lr2.predict(features_test)-1).sum()*-1))\n",
    "print('test set positive class predictions: '+str((lr2.predict(features_test)).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.75      0.37      8929\n",
      "          1       0.90      0.50      0.64     41545\n",
      "\n",
      "avg / total       0.79      0.54      0.59     50474\n",
      "\n",
      "kNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.79      0.30      8929\n",
      "          1       0.86      0.27      0.41     41545\n",
      "\n",
      "avg / total       0.74      0.36      0.39     50474\n",
      "\n",
      "RF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.88      0.35      8929\n",
      "          1       0.92      0.31      0.46     41545\n",
      "\n",
      "avg / total       0.80      0.41      0.44     50474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# note - use this formatting for cleaner output\n",
    "\n",
    "GNB2 = GaussianNB().fit(features_res2,targets_res2)\n",
    "KNN2 = KNeighborsClassifier().fit(features_res2,targets_res2)\n",
    "RF2 = RandomForestClassifier(n_estimators=64).fit(features_res2,targets_res2)\n",
    "\n",
    "print('GNB')\n",
    "print(classification_report(targets_test,GNB2.predict(features_test)))\n",
    "print('kNN')\n",
    "print(classification_report(targets_test,KNN2.predict(features_test)))\n",
    "print('RF')\n",
    "print(classification_report(targets_test,RF2.predict(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regardless of undersampling ratio, precision is fairly poor across the board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we do not explore simple oversampling of the minority class.. known tendency to cause models to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Manipulation Approach 2: SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
