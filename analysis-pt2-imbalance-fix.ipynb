{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select(query):\n",
    "    \n",
    "    conn = sqlite3.connect('./data/lending-club-loan-data/database2.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    temp_df = pd.DataFrame(cursor.execute(query).fetchall())\n",
    "    temp_df.columns = list(map(lambda x: x[0], cursor.description))\n",
    "    conn.close()\n",
    "    \n",
    "    return temp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans = select('SELECT * FROM LOAN_FINAL')\n",
    "loans = loans.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separating the data into the first general problem at hand: \"Matured Loans\" \n",
    "\n",
    "loans = loans[(loans['loan_status']=='Charged Off') | (loans['loan_status']=='Fully Paid')].copy()\n",
    "features = loans.drop('loan_status',axis=1).copy()\n",
    "targets = loans['loan_status'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map targets to 0/1 and perform train-test split on the data. test set to be untouched until final application of models\n",
    "\n",
    "outputmap = {'Charged Off':0,'Fully Paid':1}\n",
    "targets = targets.apply(lambda x: outputmap[x])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features,targets,random_state=12,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# develop lists which split up features into numerical and non-numerical values\n",
    "# should do this in the processing step...\n",
    "\n",
    "\n",
    "numerical = []\n",
    "strings = []\n",
    "\n",
    "for i in range(len(loans.dtypes)):\n",
    "    if (loans.dtypes[i] == 'int64') or (loans.dtypes[i] == 'float64'):\n",
    "        numerical = numerical + [loans.dtypes.index[i]]\n",
    "        \n",
    "    if (loans.dtypes[i] == 'O') and (loans.dtypes.index[i]!='loan_status'):\n",
    "        strings = strings + [loans.dtypes.index[i]]\n",
    "        \n",
    "numerical_all = list(numerical)\n",
    "\n",
    "numerical_all.remove('mths_since_last_delinq')\n",
    "numerical_all.remove('mths_since_last_major_derog')\n",
    "numerical_all.remove('member_id')\n",
    "\n",
    "numerical.remove('mths_since_last_delinq')\n",
    "numerical.remove('mths_since_last_major_derog')\n",
    "numerical.remove('member_id')\n",
    "numerical.remove('delinq_2yrs')\n",
    "numerical.remove('inq_last_6mths')\n",
    "numerical.remove('out_prncp')\n",
    "numerical.remove('out_prncp_inv')\n",
    "numerical.remove('total_pymnt')\n",
    "numerical.remove('total_pymnt_inv')\n",
    "numerical.remove('total_rec_prncp')\n",
    "numerical.remove('total_rec_int')\n",
    "numerical.remove('total_rec_late_fee')\n",
    "numerical.remove('recoveries')\n",
    "numerical.remove('collection_recovery_fee')\n",
    "numerical.remove('last_pymnt_amnt')\n",
    "numerical.remove('collections_12_mths_ex_med')\n",
    "numerical.remove('tot_coll_amt')\n",
    "numerical.remove('mths_since_issue')\n",
    "numerical.remove('mths_left')\n",
    "numerical.remove('%_term_completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groups dataset into categorically similar subsets and gathers their means for value filling\n",
    "# this function is specific to this application..may be worth further generalizing\n",
    "\n",
    "def NaN_estimator(dataframe,column):\n",
    "    \n",
    "    filled_dataframe = dataframe.copy()\n",
    "\n",
    "    datasubset = dataframe[['grade','home_ownership','initial_list_status','purpose',column]].copy()\n",
    "    means = datasubset.groupby(by=['grade','home_ownership','initial_list_status','purpose']).mean()\n",
    "\n",
    "    subset_estimates = []\n",
    "\n",
    "    for i in dataframe[dataframe[column].isnull()].index:\n",
    "    \n",
    "        tuple_temp = (dataframe.loc[i,'grade'],dataframe.loc[i,'home_ownership'],\n",
    "                      dataframe.loc[i,'initial_list_status'],dataframe.loc[i,'purpose'])\n",
    "    \n",
    "        subset_estimates = subset_estimates + [means.loc[tuple_temp,column]]\n",
    "    \n",
    "    filled_dataframe.loc[list(dataframe[dataframe[column].isnull()].index),column] = subset_estimates\n",
    "    \n",
    "    return filled_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train = NaN_estimator(features_train,'revol_util')\n",
    "features_train.loc[features_train[features_train.revol_util.isnull()].index,'revol_util'] = features_train.revol_util.mean()\n",
    "\n",
    "features_test = NaN_estimator(features_test,'revol_util')\n",
    "features_test.loc[features_test[features_test.revol_util.isnull()].index,'revol_util'] = features_test.revol_util.mean()\n",
    "\n",
    "features_train = NaN_estimator(features_train,'tot_coll_amt')\n",
    "features_train.loc[features_train[features_train.tot_coll_amt.isnull()].index,'tot_coll_amt'] = \\\n",
    "    features_train.tot_coll_amt.mean()\n",
    "\n",
    "features_test = NaN_estimator(features_test,'tot_coll_amt')\n",
    "features_test.loc[features_test[features_test.tot_coll_amt.isnull()].index,'tot_coll_amt'] = \\\n",
    "    features_test.tot_coll_amt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2153942473241268"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data has approx 1:5 ratio of minority to majority class examples\n",
    "\n",
    "ratio = -1*((targets_train-1).sum())/targets_train.sum()\n",
    "-1*((targets_train-1).sum())/targets_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_dict1: undersample the majority class to create a 1:1 ratio of minority to majority class examples\n",
    "# ratio_dict2: undersample the majority class to create a 2:1 ratio of minority to majority class examples\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ratio_dict1 = {0:len(features_train[~targets_train.astype(bool)]),1:len(features_train[~targets_train.astype(bool)])}\n",
    "ratio_dict2 = {0:len(features_train[~targets_train.astype(bool)]),1:round((.5*len(features_train[~targets_train.astype(bool)])))}\n",
    "\n",
    "features_res1, targets_res1 = RandomUnderSampler(ratio=ratio_dict1,random_state=2)\\\n",
    "    .fit_sample(features_train[numerical],targets_train)\n",
    "    \n",
    "features_res2, targets_res2 = RandomUnderSampler(ratio=ratio_dict2,random_state=2)\\\n",
    "    .fit_sample(features_train[numerical],targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1:1 minority to majority class undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641775963863\n"
     ]
    }
   ],
   "source": [
    "# accuracy considerably drops -- this same baseline model in pt1 had 82% accuracy on the test set\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_res1,targets_res1)\n",
    "print(accuracy_score(lr.predict(features_test[numerical]),targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.64      0.64     35780\n",
      "          1       0.64      0.65      0.65     35780\n",
      "\n",
      "avg / total       0.64      0.64      0.64     71560\n",
      "\n",
      "TEST             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.63      0.38      8929\n",
      "          1       0.89      0.64      0.75     41545\n",
      "\n",
      "avg / total       0.78      0.64      0.68     50474\n",
      "\n",
      "test set negative class predictions: 20448\n",
      "test set positive class predictions: 30026\n"
     ]
    }
   ],
   "source": [
    "# precision drops from 50% to 28%, but this model in pt1 only made 4 negative class predictions. there remains room for\n",
    "# improvement in precision, but model has become much more sensitive to outputting the minority class\n",
    "# recall is GREATLY improved -- this model in pt1 has close to 0% recall on the test set\n",
    "\n",
    "print('TRAIN'+classification_report(targets_res1,lr.predict(features_res1)))\n",
    "print('TEST'+classification_report(targets_test,lr.predict(features_test[numerical])))\n",
    "\n",
    "print('test set negative class predictions: '+str((lr.predict(features_test[numerical])-1).sum()*-1))\n",
    "print('test set positive class predictions: '+str((lr.predict(features_test[numerical])).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2:1 minority to majority class undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278341324246\n"
     ]
    }
   ],
   "source": [
    "# accuracy is concerningly low..perhaps we are sacrificing too much in the recall of positive examples\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(features_res2,targets_res2)\n",
    "print(accuracy_score(lr2.predict(features_test[numerical]),targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.96      0.80     35780\n",
      "          1       0.62      0.13      0.22     17890\n",
      "\n",
      "avg / total       0.67      0.68      0.61     53670\n",
      "\n",
      "TEST             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.96      0.32      8929\n",
      "          1       0.94      0.13      0.23     41545\n",
      "\n",
      "avg / total       0.81      0.28      0.25     50474\n",
      "\n",
      "test set negative class predictions: 44622\n",
      "test set positive class predictions: 5852\n"
     ]
    }
   ],
   "source": [
    "# recall on the negative class is extremely good, but we have sacrificed too much predictability on the majority class\n",
    "# (the negative class precision is quite low on the test set..the model is now insensitive to positive predictions)\n",
    "\n",
    "# there seems to be a balance that we can achieve between metric performance on positive/negative examples\n",
    "# by changing the ratio of minority to majority class examples, but ideally we want to perform well on both\n",
    "\n",
    "# rather than simply adjusting the ratio of class examples, we move onto other resampling techniques and applying\n",
    "# different algorithms w/ hyperparameter optimization to aim for better performance on both metrics on both classes\n",
    "\n",
    "print('TRAIN'+classification_report(targets_res2,lr2.predict(features_res2)))\n",
    "print('TEST'+classification_report(targets_test,lr2.predict(features_test[numerical])))\n",
    "\n",
    "print('test set negative class predictions: '+str((lr2.predict(features_test[numerical])-1).sum()*-1))\n",
    "print('test set positive class predictions: '+str((lr2.predict(features_test[numerical])).sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
